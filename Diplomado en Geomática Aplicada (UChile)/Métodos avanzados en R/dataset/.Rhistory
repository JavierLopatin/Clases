mmMatrix <- matrix(c("PerceivedVisualComplexity","VX.0","F",
"PerceivedVisualComplexity","VX.1","F",
"PerceivedVisualComplexity","VX.2","F",
"PerceivedVisualComplexity","VX.3","F",
"PerceivedVisualComplexity","VX.4","F",
"Arousal","Aro1","F",
"Arousal","Aro2","F",
"Arousal","Aro3","F",
"Arousal","Aro4","F",
"ApproachAvoidance","AA.0","R",
"ApproachAvoidance","AA.1","R",
"ApproachAvoidance","AA.2","R",
"ApproachAvoidance","AA.3","R"),nrow=13,ncol=3,byrow =TRUE,
dimnames = list(1:13,c("latent","measurement","type")))
plsModel<-simplePLS(trainData,smMatrix,mmMatrix,300,7)
#Get results from model
smMatrix <- plsModel$smMatrix
mmMatrix <- plsModel$mmMatrix
ltVariables <- plsModel$ltVariables
mmVariables <- plsModel$mmVariables
outer_weights <- plsModel$outer_weights
outer_loadings <- plsModel$outer_loadings
meanData<-plsModel$meanData
sdData <- plsModel$sdData
path_coef<-plsModel$path_coef
#Create container for Exogenous Variables
exVariables = NULL
#Create container for Endogenous Variables
enVariables = NULL
#Identify Exogenous and Endogenous Variables
exVariables <- unique(smMatrix[,1])
pMeasurements <- NULL
for (i in 1:length(exVariables)){
pMeasurements <- c(pMeasurements,mmMatrix[mmMatrix[,"latent"]==exVariables[i],"measurement"])
}
enVariables <- unique(smMatrix[,2])
resMeasurements <- NULL
for (i in 1:length(enVariables)){
resMeasurements <- c(resMeasurements, mmMatrix[mmMatrix[, "latent"] == enVariables[i],"measurement"])
}
enVariables <- setdiff(enVariables,exVariables)
eMeasurements <- NULL
for (i in 1:length(enVariables)){
eMeasurements <- c(eMeasurements, mmMatrix[mmMatrix[, "latent"] == enVariables[i],"measurement"])
}
#Extract Measurements needed for Predictions
normData <- testData[, pMeasurements]
#Normalize data
for (i in pMeasurements)
{
normData[,i] <-(normData[,i] - meanData[i])/sdData[i]
}
#Convert dataset to matrix
normData<-data.matrix(normData)
#Add empty columns to normData for the estimated measurements
for (i in 1:length(eMeasurements))
{
normData = cbind(normData, seq(0,0,length.out =nrow(normData)))
colnames(normData)[length(colnames(normData))]=eMeasurements[i]
}
#Estimate Factor Scores from Outter Path
fscores <- normData%*%outer_weights
fscores
#Estimate Factor Scores from Inner Path and complete Matrix
fscores <- fscores + fscores%*%path_coef
fscores
#Estimate Factor Scores from Outter Path
fscores <- normData%*%outer_weights
fscores
fscores
fscores%*%path_coef
path_coef
fscores
#Estimate Factor Scores from Outter Path
fscores <- normData%*%outer_weights
#Estimate Factor Scores from Inner Path and complete Matrix
fscores <- fscores + fscores%*%path_coef
fscores
#Predict Measurements with loadings
predictedMeasurements<-fscores%*% t(outer_loadings)
predictedMeasurements
t(outer_loadings)
fscores%*% t(outer_loadings)
View(PLSpredict)
load("~/Documents/PhD/Peatland/Managements_difference/compare.RData")
pls=PLS
if (class(pls) != "plspm")
stop("\n'plspmPredict()' requires a 'plspm' object")
if (all(class(dat) != "data.frame" && class(dat) != "RasterStack" && class(dat) != "RasterBrick"))
stop("\n'plspmPredict()' requires a 'data.frame', 'RasterStack', or 'RasterBrick' object")
# Determine method
if (class (dat) ==  "data.frame") method <- 'dat'
if (class (dat) == 'RasterBrick') method <- 'rst'
if (class (dat) == 'RasterStack') method <- 'rst'
pls
dat=test
if (class(pls) != "plspm")
stop("\n'plspmPredict()' requires a 'plspm' object")
if (all(class(dat) != "data.frame" && class(dat) != "RasterStack" && class(dat) != "RasterBrick"))
stop("\n'plspmPredict()' requires a 'data.frame', 'RasterStack', or 'RasterBrick' object")
# Determine method
if (class (dat) ==  "data.frame") method <- 'dat'
if (class (dat) == 'RasterBrick') method <- 'rst'
if (class (dat) == 'RasterStack') method <- 'rst'
# from plspm object
ltVariables <- pls$model$gen$lvs_names # latent variables
mmVariables <- pls$model$gen$mvs_names # measurement variables
path_coef   <- pls$path_coefs # path coefficients
# Extract and Normalize the measurements for the model
normDataTrain <- scale(pls$data[, mmVariables], TRUE, TRUE)
# Extract Mean and Standard Deviation of measurements for future prediction
meanData <- attr(normDataTrain, "scaled:center")
sdData   <- attr(normDataTrain, "scaled:scale")
# get relationship matrix
mmMatrix = matrix(nrow = length(mmVariables),
ncol = 2, byrow =TRUE,
dimnames = list(1:length(mmVariables), c("latent","measurement")))
mmMatrix[,'latent'] = as.character(pls$outer_model[,2])
mmMatrix[,'measurement'] = as.character(pls$outer_model[,1])
# Create a matrix of outer_weights
outer_weights <- matrix(data=0,
nrow=length(mmVariables),
ncol=length(ltVariables),
dimnames = list(mmVariables,ltVariables))
#Initialize outer_weights matrix with value 1 for each relationship in the measurement model
for (i in 1:length(ltVariables))  {
outer_weights [mmMatrix[mmMatrix[,"latent"]==ltVariables[i],
"measurement"],
ltVariables[i]] = 1
}
# get relationship matrix
smMatrix = matrix(nrow = length(pls$effects[,1]),
ncol = 2, byrow =TRUE,
dimnames = list(1:length(pls$effects[,1]), c("source","target")))
for (i in 1:length(pls$effects[,1])){
exVar = strsplit(as.character(pls$effects[,1][i]), "[-->]")[[1]][1]
enVar = strsplit(as.character(pls$effects[,1][i]), "[-->]")[[1]][3]
smMatrix[i,1] <- gsub(" ", "", exVar, fixed = TRUE)
smMatrix[i,2] <- gsub(" ", "", enVar, fixed = TRUE)
}
# Create a matrix of outer_loadins
outer_loadings <- matrix(data=0,
nrow=length(mmVariables),
ncol=length(ltVariables),
dimnames = list(mmVariables,ltVariables))
for (i in 1:length(ltVariables))  {
mesVar = mmMatrix[mmMatrix[,"latent"]==ltVariables[i], "measurement"]
idx = which(pls$outer_model$name %in% mesVar)
outer_loadings[mesVar , ltVariables[i]] = pls$outer_model$loading[idx]
}
# Identify Exogenous and Endogenous Variables
exVariables <- unique(smMatrix[,1])
pMeasurements <- NULL
for (i in 1:length(exVariables)){
pMeasurements <- c(pMeasurements,mmMatrix[mmMatrix[,"latent"]==exVariables[i],"measurement"])
}
enVariables <- unique(smMatrix[,2])
resMeasurements <- NULL
for (i in 1:length(enVariables)){
resMeasurements <- c(resMeasurements, mmMatrix[mmMatrix[, "latent"] == enVariables[i],"measurement"])
}
enVariables <- setdiff(enVariables,exVariables)
eMeasurements <- NULL
for (i in 1:length(enVariables)){
eMeasurements <- c(eMeasurements, mmMatrix[mmMatrix[, "latent"] == enVariables[i],"measurement"])
}
# Extract Measurements needed for Predictions
if (method == 'dat'){
normData <- dat[, pMeasurements]
# Normalize data
for (i in pMeasurements){
normData[,i] <- (normData[,i] - meanData[i])/sdData[i]
# Convert dataset to matrix
normData <- data.matrix(normData)
# Add empty columns to normData for the estimated measurements
for (i in 1:length(eMeasurements)){
normData = cbind(normData, seq(0,0,length.out = nrow(normData)))
colnames(normData)[length(colnames(normData))] = eMeasurements[i]
}
}
}
if (method == 'rst'){
names(dat) = pMeasurements
normData <- (dat[[1]] - meanData[1])/sdData[1]
for (i in 2:length(pMeasurements)){
#normData[[i]] <- (dat[[i]] - meanData[i])/sdData[i]
normData <- addLayer(normData, (dat[[i]] - meanData[i])/sdData[i])
}
}
# Estimate Factor Scores from Outer Path
if (method == 'dat'){
fscores <- normData %*% outer_weights
# Estimate Factor Scores from Inner Path and complete Matrix
fscores <- fscores + fscores %*% t(path_coef)
}
normData
outer_weights
fscores <- normData %*% outer_weights
fscores
normData
# Extract Measurements needed for Predictions
if (method == 'dat'){
normData <- dat[, pMeasurements]
# Normalize data
for (i in pMeasurements){
normData[,i] <- (normData[,i] - meanData[i])/sdData[i]
# Convert dataset to matrix
normData <- data.matrix(normData)
# Add empty columns to normData for the estimated measurements
for (i in 1:length(eMeasurements)){
normData = cbind(normData, seq(0,0,length.out = nrow(normData)))
colnames(normData)[length(colnames(normData))] = eMeasurements[i]
}
}
}
normData
normData %*% outer_weights
normData <- dat[, pMeasurements]
# Normalize data
for (i in pMeasurements){
normData[,i] <- (normData[,i] - meanData[i])/sdData[i]
# Convert dataset to matrix
normData <- data.matrix(normData)
# Add empty columns to normData for the estimated measurements
for (i in 1:length(eMeasurements)){
normData = cbind(normData, seq(0,0,length.out = nrow(normData)))
colnames(normData)[length(colnames(normData))] = eMeasurements[i]
}
# Estimate Factor Scores from Outer Path
fscores <- normData %*% outer_weights
# Estimate Factor Scores from Inner Path and complete Matrix
fscores <- fscores + fscores %*% t(path_coef)
}
normData <- dat[, pMeasurements]
# Normalize data
for (i in pMeasurements){
normData[,i] <- (normData[,i] - meanData[i])/sdData[i]
}
# Convert dataset to matrix
normData <- data.matrix(normData)
# Add empty columns to normData for the estimated measurements
for (i in 1:length(eMeasurements)){
normData = cbind(normData, seq(0,0,length.out = nrow(normData)))
colnames(normData)[length(colnames(normData))] = eMeasurements[i]
}
normData
normData %*% outer_weights
# Estimate Factor Scores from Outer Path
fscores <- normData %*% outer_weights
outer_weights
# Estimate Factor Scores from Inner Path and complete Matrix
fscores <- fscores + fscores %*% t(path_coef)
fscores
# Extract Measurements needed for Predictions
if (method == 'dat'){
normData <- dat[, pMeasurements]
# Normalize data
for (i in pMeasurements){
normData[,i] <- (normData[,i] - meanData[i])/sdData[i]
}
# Convert dataset to matrix
normData <- data.matrix(normData)
# Add empty columns to normData for the estimated measurements
for (i in 1:length(eMeasurements)){
normData = cbind(normData, seq(0,0,length.out = nrow(normData)))
colnames(normData)[length(colnames(normData))] = eMeasurements[i]
}
# Estimate Factor Scores from Outer Path
fscores <- normData %*% outer_weights
# Estimate Factor Scores from Inner Path and complete Matrix
fscores <- fscores + fscores %*% t(path_coef)
# Predict Measurements with loadings
predictedMeasurements <- fscores %*% t(outer_loadings)
# Denormalize data
for (i in mmVariables){
predictedMeasurements[,i]<-(predictedMeasurements[,i] * sdData[i]) + meanData[i]
}
# Calculating the measurement residuals and accuracies if validation data is provided
if (!is.na(sum( match( eMeasurements, colnames(dat) ) ))){ # if validation data is presented for the endogenous variables
# measurement variables data
mmData = dat[, eMeasurements]
# get residuals
mmResiduals <- dat[,resMeasurements] - predictedMeasurements[,resMeasurements]
# get accuracies of measurement predictions
fit_measurements <- matrix(ncol=length(resMeasurements), nrow = 4, byrow = T)
colnames(fit_measurements) <- resMeasurements
rownames(fit_measurements) <- c('r_square','RMSE','nRMSE','bias')
for (i in 1:length(resMeasurements)){
fit_measurements[1,i] <- cor(dat[,resMeasurements[i]], predictedMeasurements[,resMeasurements[i]], method="pearson")
fit_measurements[2,i] <- sqrt(mean((dat[,resMeasurements[i]] - predictedMeasurements[,resMeasurements[i]])^2))
fit_measurements[3,i] <- (fit_measurements[2,i]/(max(dat[,resMeasurements[i]]) - min(dat[,resMeasurements[i]])))*100
lm = lm(predictedMeasurements[,resMeasurements[i]] ~ dat[,resMeasurements[i]]-1)
fit_measurements[4,i] <- 1-coef(lm)
}
} else {
mmData = dat[,pMeasurements]
residuals = NA
fit_measurements = NA
}
# Prepare return Object
predictResults <- list(mmData = mmData,
mmPredicted = predictedMeasurements[,resMeasurements],
mmResiduals = mmResiduals,
mmfit = fit_measurements,
Scores = fscores)
}
predictResults
outer_weights
# Estimate Factor Scores from Outer Path
fscores <- normData %*% outer_weights
fscores
t(outer_loadings)
t(path_coef)
t(path_coef)
# Estimate Factor Scores from Outer Path
fscores <- normData %*% outer_weights
fscores
fscores %*% t(path_coef)
fscores
t(path_coef)
eMeasurements
enVariables
enVariables
eMeasurements
mmVariables
enVariables
mmVariables
install.packages('caret')
library(caret)
library(caret)
setwd('/home/javier/Documents/Clases/Diplomado GEP/dataset')
data = read.csv('angers-leaf-optical-properties-database--2003.csv')
data = data[data$Measurement_type == 'reflectance', ]
colnames(data)
traits = data[c(2,4,7,9,15)]
colnames(traits) = c('Car', 'Cab', 'Cw', 'Cm', 'N')
min(traits$Cm); max(traits$Cm)
reflec = data[, 22:ncol(data)]
plot(seq(400,2450), colMeans(reflec), type='l', las=1, lwd=2, ylab='Reflectance', xlab='Wavelength [nm]',
main="Reflectancia media")
# primero verificar que los datos no tengan NaNs
any(is.na(reflec))
# como recomendación, siempre utilicen scale=TRUE para normalizar las variables a unidades de desviación estandar
# PCA se ve afectado grandemente por diferencia en unidades entrevariables. Es este caso particular no es tan terrible,
# ya que todas las variables tienen la misma unidad de medida, pero es buena práctiva nrmalizarlas de todas formas.
pca <- prcomp(reflect, scale=TRUE)
# como recomendación, siempre utilicen scale=TRUE para normalizar las variables a unidades de desviación estandar
# PCA se ve afectado grandemente por diferencia en unidades entrevariables. Es este caso particular no es tan terrible,
# ya que todas las variables tienen la misma unidad de medida, pero es buena práctiva nrmalizarlas de todas formas.
pca <- prcomp(reflec, scale=TRUE)
pca
names(pca)
pca$rotation
head(pca$rotation)
pca$rotation[1:5,1:5]
pca$rotation[1:10,1:10]
pca$rotation[1:10,1:6]
pca$x[1:10,1:6]
pca$x
pca$x[1:10,1:6]
summary(pca)
summary(pca)[,1:10]
summary(pca)[1:10,]
summary(pca)
summary(pca)[1,]
summary(pca)[1]
summary(pca)[2]
summary(pca)[3]
manes(summary(pca))
names(summary(pca))
names(pca)
summary(pca)['importance']
summary(pca)['importance'][1,]
prop_varianza <- pca$sdev^2 / sum(pca$sdev^2)
prop_varianza
prop_varianza[1:10]
prop_varianza_acum <- cumsum(prop_varianza)
prop_varianza_acum
plot(seq(1,20), prop_varianza_acum[1:20])
plot(seq(1,20), prop_varianza_acum[1:20], las=1, type='l')
plot(seq(1,20), prop_varianza_acum[1:20], las=1, type='l', xlab='Componentes', ylab="Componente principal")
plot(seq(1,20), prop_varianza_acum[1:20], las=1, type='l', xlab='Componentes', ylab="Prop. varianza explicada acumulada [%]")
abline(v=3)
plot(seq(1,20), prop_varianza_acum[1:20], las=1, type='l', xlab='Componentes', ylab="Prop. varianza explicada acumulada [%]")
abline(v=3, lty=2)
prop_varianza_acum <- cumsum(prop_varianza)
plot(seq(1,20), prop_varianza_acum[1:20], las=1, type='l', xlab='Componentes', ylab="Prop. varianza acumulada [%]")
abline(v=3, lty=2)
biplot(x = pca, scale = 0, cex = 0.6, col = c("blue4", "brown3"))
plot(pca$x[,1:2])
library(vegan)
fit <- envfit(pca, traits)
plot(pca$x[,1:2])
plot(fit, col = "red", lty = 2, cex = 1.5)
plot(fit, col = "red", lty = 2)
plot(pca$x[,1:2])
plot(fit, col = "red", lty = 2)
fit
plot(pca$x[,1:2], col=data$English.Name)
plot(pca$x[,1:2], col=data$Latin.Name)
plot(fit, col = "red", lty = 2)
plot(pca$x[,1:2], col=data$Latin.Name)
plot(fit, col = "red", lty = 2)
data$Latin.Name
fit
# cargar datos de biomasa, altura de vegetación, y carbono total a nivel de plot
data = read.csv('Peatland.csv')
# cargar datos de cobertura de especies
cov_data = read.csv('Cover_spp_peatland.csv')
# cargar datos de teledetección
RS = read.csv('Peatland_RSdata.csv')
plot(seq(450,950,12.5), colMeans(RS)[2:ncol(RS)], type='l', las=1, lwd=2, ylab='Reflectance',
xlab='Wavelength [nm]', main="Reflectancia media")
library(vegan)
cov_data
# cargar datos de biomasa, altura de vegetación, y carbono total a nivel de plot
data2 = read.csv('Peatland.csv')
# datos de eppresencia/cobertura de especies
head(cov_data)
# datos de eppresencia/cobertura de especies
cov_data[1:5, 1:5]
# datos de eppresencia/cobertura de especies
cov_data[1:8, 1:5]
# Seleccionar el número de k de acuerdo al stress
nmds.stress <- sapply(1:6, function(x) metaMDS(cov_data[,2:ncol(cov_data)], distance='Jaccard', k=x)$stress)
x=2
metaMDS(cov_data[,2:ncol(cov_data)], distance='Jaccard', k=x)
metaMDS(cov_data[,2:ncol(cov_data)], distance='jaccard', k=x)
# Seleccionar el número de k de acuerdo al stress
nmds.stress <- sapply(1:6, function(x) metaMDS(cov_data[,2:ncol(cov_data)], distance='jaccard', k=x)$stress)
plot(1:6, nmds.stress)
plot(1:6, nmds.stress, sttle-'l')
plot(1:6, nmds.stress, style='l')
plot(1:6, nmds.stress)
plot(1:6, nmds.stress, xlab="Número de componentes", ylab='Stress')
nmds <- metaMDS(cov_data[,2:ncol(cov_data)], distance='jaccard', k=2, trymax=1000)
nmds$stress
nmds <- metaMDS(cov_data[,2:ncol(cov_data)], distance='jaccard', k=3, trymax=1000)
nmds$stress
nmds
summary(nmds)
stressplot(nmds)
nmds <- metaMDS(cov_data[,2:ncol(cov_data)], distance='jaccard', k=2, trymax=1000)
stressplot(nmds)
nmds <- metaMDS(cov_data[,2:ncol(cov_data)], distance='jaccard', k=3, trymax=1000)
stressplot(nmds)
plot(nmds)
plot(nmds, type='t')
scores(mnds)
scores(nmds)
plot(nmds, type='points')
# K-means
library(NbClust)
numero_clusters <- NbClust(data = scores(nmds), distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans", index = "alllong")
fviz_nbclust(numero_clusters)
conda install -c conda-forge r-factoextra
# K-means
library(factoextra)
fviz_nbclust(numero_clusters)
kmeans(x=scores(nmds), centers=4)
cluster <- kmeans(x=scores(nmds), centers=4)
cluster$cluster
data2
# datos observados (Altura vegetación, biomasa, riqueza, y carbono)
obs_data = data2[,c(4:7)]
colnames(obs_data)
# obtener gradientes de altura de vegetacion
fit <- envfit(nmds, obs_data)
fit
# plot todo junto
plot(scores(nmds[,1:2]))
# plot todo junto
plot(scores(nmds)[,1:2])
# plot todo junto
plot(scores(nmds)[,1:2])
# plot todo junto
plot(scores(nmds)[,1:2], col=cluster$cluster)
# plot todo junto
plot(scores(nmds)[,1:2], col=cluster$cluster, pch=16)
plot(fit)
# plot componentes y colores por clusters
plot(scores(nmds)[,1:2], col=cluster$cluster, pch=16)
# plot environmental fits
plot(fit, col = "red", lty = 2)
colnames(obs_data)
colnames(obs_data) <- c('H', 'BM', 'C', 'Riq.')
# obtener gradientes de altura de vegetacion
fit <- envfit(nmds, obs_data)
# K-means con 4 clusters
cluster <- kmeans(x=scores(nmds), centers=4)
# plot componentes y colores por clusters
plot(scores(nmds)[,1:2], col=cluster$cluster, pch=16)
# plot environmental fits
plot(fit, col = "red", lty = 2)
# cargar datos de biomasa, altura de vegetación, y carbono total a nivel de plot
data2 = read.csv('Peatland.csv')
# cargar datos de cobertura de especies
cov_data = read.csv('Cover_spp_peatland.csv')
# cargar datos de teledetección
RS = read.csv('Peatland_RSdata.csv')
plot(seq(450,950,12.5), colMeans(RS)[2:ncol(RS)], type='l', las=1, lwd=2, ylab='Reflectance',
xlab='Wavelength [nm]', main="Reflectancia media")
# datos observados (Altura vegetación, biomasa, riqueza, y carbono)
obs_data = data2[,c(4:7)]
colnames(obs_data) <- c('H', 'BM', 'C', 'Riq.') # solo para abreviar
# obtener gradientes de altura de vegetacion
fit <- envfit(nmds, obs_data)
# plot componentes y colores por clusters
plot(scores(nmds)[,1:2], col=cluster$cluster, pch=16)
# plot environmental fits
plot(fit, col = "red", lty = 2)
